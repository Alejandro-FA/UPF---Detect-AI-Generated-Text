import torch
import shap
import streamlit as st
from transformers import Pipeline
from typing import Optional

def get_torch_device(use_gpu: bool = True, debug: bool = False) -> torch.device:
    """Obtains a torch device in which to perform computations

    Args:
        use_gpu (bool, optional): Use GPU if available. Defaults to True.
        debug (bool, optional): Whether to print debug information or not. Defaults to False.

    Returns:
        torch.device: Device in which to perform computations
    """    
    device = torch.device(
        'cuda:0' if use_gpu and torch.cuda.is_available() else
        'mps' if use_gpu and torch.backends.mps.is_available() else
        'cpu'
    )
    if debug: print("Device selected:", device)
    return device

@st.cache_data
def compute_prediction(text: str, _classifier: Pipeline, _explainer: shap.Explainer) -> None:
    st.session_state['prediction'] = _classifier(text)
    st.session_state['shap_values'] = _explainer([text])



if __name__ == '__main__':
    import streamlit as st
    from streamlit_shap import st_shap
    from transformers import pipeline
    import os
    import shap

    ############################ SECTION 00 ###################################
    # Load AI-generatet text classification model
    model_path = os.path.abspath('model')
    classifier = pipeline(
        'text-classification',
        model=model_path,
        device=get_torch_device(debug=True),
        top_k=1,
        truncation=True,
        padding=True,
    )
    
    # Create SHAP explainer
    explainer = shap.Explainer(classifier)

    # Initialize session state
    if 'prediction' not in st.session_state:
        st.session_state['prediction'] = None
    if 'shap_values' not in st.session_state:
        st.session_state['shap_values'] = None

    ############################ SECTION 01 ###################################
    st.title("Check whether an essay has been generated by AI or not ðŸ¤–")
    st.write('\n')

    # Input text
    txt = st.text_area(
        "Enter text to check",
        max_chars=2500,
        height=200,
        placeholder="Copy the text that you want to check here.",
        label_visibility="collapsed",
        on_change=lambda: compute_prediction(st.session_state['text_input'], classifier, explainer),
        key="text_input",
    )

    #Â Submit button
    st.write('\n')
    col1, col2, col3, col4, col5 = st.columns(5)
    if col3.button('Check text', type='primary', use_container_width=True):
        compute_prediction(txt, classifier, explainer)


    ############################ SECTION 02 ###################################
    st.write('\n')
    st.write('\n')
    prediction = st.session_state['prediction']
    shap_values = st.session_state['shap_values']

    if prediction and shap_values:
        # Display prediction result
        prob = round(prediction[0][0]['score'] * 100, 2)
        if prediction[0][0]['label'] == 'human': prob = 100 - prob
        st.subheader(f'There is a :blue[{prob}%] chance that this text has been generated by an AI model.')

        # Explainable AI plots
        st_shap(shap.plots.text(shap_values[:,:,'ai']), height=300)
        st_shap(shap.plots.bar(shap_values[0, :, "ai"]))
